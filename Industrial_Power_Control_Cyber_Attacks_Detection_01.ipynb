{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import javabridge\n",
    "import weka.core.jvm as jvm\n",
    "from weka.classifiers import Classifier\n",
    "from weka.core.converters import Loader\n",
    "import weka.filters as filters\n",
    "from weka.classifiers import Evaluation\n",
    "from weka.filters import Filter\n",
    "from weka.attribute_selection import ASSearch, ASEvaluation, AttributeSelection\n",
    "import random\n",
    "from weka.core.classes import Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weka.core.jvm as jvm\n",
    "jvm.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of dataset filenames\n",
    "dataset_filenames = ['data1 Sampled Scenarios.csv.arff', 'data2 Sampled Scenarios.csv.arff', 'data3 Sampled Scenarios.csv.arff', 'data4 Sampled Scenarios.csv.arff', 'data5 Sampled Scenarios.csv.arff',\n",
    "                     'data6 Sampled Scenarios.csv.arff', 'data7 Sampled Scenarios.csv.arff', 'data8 Sampled Scenarios.csv.arff', 'data9 Sampled Scenarios.csv.arff', 'data10 Sampled Scenarios.csv.arff',\n",
    "                     'data11 Sampled Scenarios.csv.arff', 'data12 Sampled Scenarios.csv.arff', 'data13 Sampled Scenarios.csv.arff', 'data14 Sampled Scenarios.csv.arff', 'data15 Sampled Scenarios.csv.arff']\n",
    "dataset_filenames = [\"Class/multiclass/\" + filename for filename in dataset_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JRipper\n",
    "loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n",
    "for filename in dataset_filenames:\n",
    "  data = loader.load_file(filename)\n",
    "  data.class_is_last()\n",
    "  # Split the selected dataset into training and testing sets\n",
    "  train, test = data.train_test_split(80)\n",
    "  # Build the classifier on the training data\n",
    "  #To optimize the accuracy more increase -f values decrease -n value and increase -0 values\n",
    "  cls = Classifier(classname=\"weka.classifiers.rules.JRip\", options=[\"-F\", \"3\", \"-N\", \"2.0\", \"-O\", \"2\"])\n",
    "  cls.build_classifier(train)\n",
    "  eval = Evaluation(train)\n",
    "  random.seed(1)\n",
    "  eval.crossvalidate_model(cls, test, 2, Random(1))\n",
    "  print(eval.percent_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jripper + Adaboost\n",
    "loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n",
    "for filename in dataset_filenames:\n",
    "  data = loader.load_file(filename)\n",
    "  data.class_is_last()\n",
    "  # split the selected dataset into training and testing sets\n",
    "  train, test = data.train_test_split(80)\n",
    "\n",
    "  # create a new Evaluation object for the selected attributes\n",
    "  eval = Evaluation(train)\n",
    "\n",
    "  # build the classifier on the training data\n",
    "  #To optimize the accuracy more increase -f values decrease -n value and increase -0 values\n",
    "  base_cls = Classifier(classname=\"weka.classifiers.rules.JRip\", options=[\"-F\", \"3\", \"-N\", \"2.0\", \"-O\", \"2\"])\n",
    "  cls = Classifier(classname=\"weka.classifiers.meta.AdaBoostM1\", options=[\"-P\", \"100\", \"-S\", \"1\", \"-I\", \"10\", \"-W\", base_cls.classname, \"--\"])\n",
    "  cls.build_classifier(train)\n",
    "\n",
    "  # make predictions on the test data using the new Evaluation object\n",
    "  random.seed(1)\n",
    "  eval.crossvalidate_model(cls, test, 10, Random(1))\n",
    "  print(eval.percent_correct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
